{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b99da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from find_missing_predictions_util import find_missing_predictions\n",
    "from lags_util import create_all_advanced_lags\n",
    "from update_data_util import fetch_and_update_stock_data, update_predictions_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb300943",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_to_basename = {\n",
    "    # Indices\n",
    "    \"^NSEI\": \"NIFTY_50\",\n",
    "    \"^NSEBANK\": \"NIFTY_BANK\",\n",
    "    \"^CNXIT\": \"NIFTY_IT\",\n",
    "    \"^CNXPHARMA\": \"NIFTY_PHARMA\",\n",
    "    \"^CNXFMCG\": \"NIFTY_FMCG\",\n",
    "    \"^CNXAUTO\": \"NIFTY_AUTO\",\n",
    "    \"^CNXMETAL\": \"NIFTY_METAL\",\n",
    "    \"^CNXREALTY\": \"NIFTY_REALTY\",\n",
    "    \"^CNXENERGY\": \"NIFTY_ENERGY\",\n",
    "    \"NIFTY_FIN_SERVICE.NS\": \"NIFTY_FIN_SERVICE\",\n",
    "    \n",
    "    # Stocks\n",
    "    \"RELIANCE.NS\": \"RELIANCE_INDUSTRIES_LTD\",\n",
    "    \"TCS.NS\": \"TATA_CONSULTANCY_SERV_LT\", # Matched from your image\n",
    "    \"SUNPHARMA.NS\": \"SUN_PHARMACEUTICAL_IND_L\",\n",
    "    \"ICICIBANK.NS\": \"ICICI_BANK_LTD.\",\n",
    "    \"INFY.NS\": \"INFOSYS_LIMITED\",\n",
    "    \"SBIN.NS\": \"STATE_BANK_OF_INDIA\",\n",
    "    \"BHARTIARTL.NS\": \"BHARTI_AIRTEL_LIMITED\",\n",
    "    \"ITC.NS\": \"ITC_LTD\",\n",
    "    \"LT.NS\": \"LARSEN_&_TOUBRO_LTD.\",\n",
    "    \"HINDUNILVR.NS\": \"HINDUSTAN_UNILEVER_LTD.\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "raw_data_folder = r\"Raw_Data\"\n",
    "predicted_data_folder = r\"Pred_Data\"\n",
    "lagging_data_folder = r\"Lag_Data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b34086b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“Š Processing: ^NSEI\n",
      "ğŸ“ˆ Updating existing data for NIFTY_50...\n",
      "Last record in file is from: 2025-11-17 15:15:00+05:30\n",
      "âœ… Data updated from 2025-11-18 09:15:00+05:30 to 2025-11-20 14:15:00+05:30\n",
      "ğŸ“Š Added 20 new records\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Processing: ^NSEBANK\n",
      "ğŸ“ˆ Updating existing data for NIFTY_BANK...\n",
      "Last record in file is from: 2025-11-17 15:15:00+05:30\n",
      "âœ… Data updated from 2025-11-18 09:15:00+05:30 to 2025-11-20 14:15:00+05:30\n",
      "ğŸ“Š Added 20 new records\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Processing: ^CNXIT\n",
      "ğŸ“ˆ Updating existing data for NIFTY_IT...\n",
      "Last record in file is from: 2025-11-17 15:15:00+05:30\n",
      "âœ… Data updated from 2025-11-18 09:15:00+05:30 to 2025-11-20 14:15:00+05:30\n",
      "ğŸ“Š Added 20 new records\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Processing: ^CNXPHARMA\n",
      "ğŸ“ˆ Updating existing data for NIFTY_PHARMA...\n",
      "Last record in file is from: 2025-11-17 15:15:00+05:30\n",
      "âœ… Data updated from 2025-11-18 09:15:00+05:30 to 2025-11-20 14:15:00+05:30\n",
      "ğŸ“Š Added 20 new records\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Processing: ^CNXFMCG\n",
      "ğŸ“ˆ Updating existing data for NIFTY_FMCG...\n",
      "Last record in file is from: 2025-11-17 15:15:00+05:30\n",
      "âœ… Data updated from 2025-11-18 09:15:00+05:30 to 2025-11-20 14:15:00+05:30\n",
      "ğŸ“Š Added 20 new records\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Processing: ^CNXAUTO\n",
      "ğŸ“ˆ Updating existing data for NIFTY_AUTO...\n",
      "Last record in file is from: 2025-11-17 15:15:00+05:30\n",
      "âœ… Data updated from 2025-11-18 09:15:00+05:30 to 2025-11-20 14:15:00+05:30\n",
      "ğŸ“Š Added 20 new records\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Processing: ^CNXMETAL\n",
      "ğŸ“ˆ Updating existing data for NIFTY_METAL...\n",
      "Last record in file is from: 2025-11-17 15:15:00+05:30\n",
      "âœ… Data updated from 2025-11-18 09:15:00+05:30 to 2025-11-20 14:15:00+05:30\n",
      "ğŸ“Š Added 20 new records\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Processing: ^CNXREALTY\n",
      "ğŸ“ˆ Updating existing data for NIFTY_REALTY...\n",
      "Last record in file is from: 2025-11-17 15:15:00+05:30\n",
      "âœ… Data updated from 2025-11-18 09:15:00+05:30 to 2025-11-20 14:15:00+05:30\n",
      "ğŸ“Š Added 20 new records\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Processing: ^CNXENERGY\n",
      "ğŸ“ˆ Updating existing data for NIFTY_ENERGY...\n",
      "Last record in file is from: 2025-11-17 15:15:00+05:30\n",
      "âœ… Data updated from 2025-11-18 09:15:00+05:30 to 2025-11-20 14:15:00+05:30\n",
      "ğŸ“Š Added 20 new records\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Processing: NIFTY_FIN_SERVICE.NS\n",
      "ğŸ“ˆ Updating existing data for NIFTY_FIN_SERVICE...\n",
      "Last record in file is from: 2025-11-17 15:15:00+05:30\n",
      "âœ… Data updated from 2025-11-18 09:15:00+05:30 to 2025-11-20 14:15:00+05:30\n",
      "ğŸ“Š Added 20 new records\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Processing: RELIANCE.NS\n",
      "ğŸ“ˆ Updating existing data for RELIANCE_INDUSTRIES_LTD...\n",
      "Last record in file is from: 2025-11-17 15:15:00+05:30\n",
      "âœ… Data updated from 2025-11-18 09:15:00+05:30 to 2025-11-20 14:15:00+05:30\n",
      "ğŸ“Š Added 20 new records\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Processing: TCS.NS\n",
      "ğŸ“ˆ Updating existing data for TATA_CONSULTANCY_SERV_LT...\n",
      "Last record in file is from: 2025-11-17 15:15:00+05:30\n",
      "âœ… Data updated from 2025-11-18 09:15:00+05:30 to 2025-11-20 14:15:00+05:30\n",
      "ğŸ“Š Added 20 new records\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Processing: SUNPHARMA.NS\n",
      "ğŸ“ˆ Updating existing data for SUN_PHARMACEUTICAL_IND_L...\n",
      "Last record in file is from: 2025-11-17 15:15:00+05:30\n",
      "âœ… Data updated from 2025-11-18 09:15:00+05:30 to 2025-11-20 14:15:00+05:30\n",
      "ğŸ“Š Added 20 new records\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Processing: ICICIBANK.NS\n",
      "ğŸ“ˆ Updating existing data for ICICI_BANK_LTD....\n",
      "Last record in file is from: 2025-11-17 15:15:00+05:30\n",
      "âœ… Data updated from 2025-11-18 09:15:00+05:30 to 2025-11-20 14:15:00+05:30\n",
      "ğŸ“Š Added 20 new records\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Processing: INFY.NS\n",
      "ğŸ“ˆ Updating existing data for INFOSYS_LIMITED...\n",
      "Last record in file is from: 2025-11-17 15:15:00+05:30\n",
      "âœ… Data updated from 2025-11-18 09:15:00+05:30 to 2025-11-20 14:15:00+05:30\n",
      "ğŸ“Š Added 20 new records\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Processing: SBIN.NS\n",
      "ğŸ“ˆ Updating existing data for STATE_BANK_OF_INDIA...\n",
      "Last record in file is from: 2025-11-17 15:15:00+05:30\n",
      "âœ… Data updated from 2025-11-18 09:15:00+05:30 to 2025-11-20 14:15:00+05:30\n",
      "ğŸ“Š Added 20 new records\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Processing: BHARTIARTL.NS\n",
      "ğŸ“ˆ Updating existing data for BHARTI_AIRTEL_LIMITED...\n",
      "Last record in file is from: 2025-11-17 15:15:00+05:30\n",
      "âœ… Data updated from 2025-11-18 09:15:00+05:30 to 2025-11-20 14:15:00+05:30\n",
      "ğŸ“Š Added 20 new records\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Processing: ITC.NS\n",
      "ğŸ“ˆ Updating existing data for ITC_LTD...\n",
      "Last record in file is from: 2025-11-17 15:15:00+05:30\n",
      "âœ… Data updated from 2025-11-18 09:15:00+05:30 to 2025-11-20 14:15:00+05:30\n",
      "ğŸ“Š Added 20 new records\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Processing: LT.NS\n",
      "ğŸ“ˆ Updating existing data for LARSEN_&_TOUBRO_LTD....\n",
      "Last record in file is from: 2025-11-17 15:15:00+05:30\n",
      "âœ… Data updated from 2025-11-18 09:15:00+05:30 to 2025-11-20 14:15:00+05:30\n",
      "ğŸ“Š Added 20 new records\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Processing: HINDUNILVR.NS\n",
      "ğŸ“ˆ Updating existing data for HINDUSTAN_UNILEVER_LTD....\n",
      "Last record in file is from: 2025-11-17 15:15:00+05:30\n",
      "âœ… Data updated from 2025-11-18 09:15:00+05:30 to 2025-11-20 14:15:00+05:30\n",
      "ğŸ“Š Added 20 new records\n"
     ]
    }
   ],
   "source": [
    "# Retriving data from Yahoo API\n",
    "for ticker in ticker_to_basename:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ“Š Processing: {ticker}\")\n",
    "    try:\n",
    "        fetch_and_update_stock_data(ticker_symbol=ticker, data_dir=raw_data_folder)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error fetching {ticker}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad4974d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ”® Generating predictions for all equities...\n",
      "---> Processing NIFTY_50\n",
      "Appended 20 new entries to Pred_Data\\NIFTY_50_predictions_xgboost.csv\n",
      "    âœ… Successfully updated: NIFTY_50_predictions_xgboost.csv\n",
      "---> Processing NIFTY_BANK\n",
      "Appended 20 new entries to Pred_Data\\NIFTY_BANK_predictions_xgboost.csv\n",
      "    âœ… Successfully updated: NIFTY_BANK_predictions_xgboost.csv\n",
      "---> Processing NIFTY_IT\n",
      "Appended 20 new entries to Pred_Data\\NIFTY_IT_predictions_xgboost.csv\n",
      "    âœ… Successfully updated: NIFTY_IT_predictions_xgboost.csv\n",
      "---> Processing NIFTY_PHARMA\n",
      "Appended 20 new entries to Pred_Data\\NIFTY_PHARMA_predictions_xgboost.csv\n",
      "    âœ… Successfully updated: NIFTY_PHARMA_predictions_xgboost.csv\n",
      "---> Processing NIFTY_FMCG\n",
      "Appended 20 new entries to Pred_Data\\NIFTY_FMCG_predictions_xgboost.csv\n",
      "    âœ… Successfully updated: NIFTY_FMCG_predictions_xgboost.csv\n",
      "---> Processing NIFTY_AUTO\n",
      "Appended 20 new entries to Pred_Data\\NIFTY_AUTO_predictions_xgboost.csv\n",
      "    âœ… Successfully updated: NIFTY_AUTO_predictions_xgboost.csv\n",
      "---> Processing NIFTY_METAL\n",
      "Appended 20 new entries to Pred_Data\\NIFTY_METAL_predictions_xgboost.csv\n",
      "    âœ… Successfully updated: NIFTY_METAL_predictions_xgboost.csv\n",
      "---> Processing NIFTY_REALTY\n",
      "Appended 20 new entries to Pred_Data\\NIFTY_REALTY_predictions_xgboost.csv\n",
      "    âœ… Successfully updated: NIFTY_REALTY_predictions_xgboost.csv\n",
      "---> Processing NIFTY_ENERGY\n",
      "Appended 20 new entries to Pred_Data\\NIFTY_ENERGY_predictions_xgboost.csv\n",
      "    âœ… Successfully updated: NIFTY_ENERGY_predictions_xgboost.csv\n",
      "---> Processing NIFTY_FIN_SERVICE\n",
      "Appended 20 new entries to Pred_Data\\NIFTY_FIN_SERVICE_predictions_xgboost.csv\n",
      "    âœ… Successfully updated: NIFTY_FIN_SERVICE_predictions_xgboost.csv\n",
      "---> Processing RELIANCE_INDUSTRIES_LTD\n",
      "Appended 20 new entries to Pred_Data\\RELIANCE_INDUSTRIES_LTD_predictions_xgboost.csv\n",
      "    âœ… Successfully updated: RELIANCE_INDUSTRIES_LTD_predictions_xgboost.csv\n",
      "---> Processing TATA_CONSULTANCY_SERV_LT\n",
      "Appended 20 new entries to Pred_Data\\TATA_CONSULTANCY_SERV_LT_predictions_xgboost.csv\n",
      "    âœ… Successfully updated: TATA_CONSULTANCY_SERV_LT_predictions_xgboost.csv\n",
      "---> Processing SUN_PHARMACEUTICAL_IND_L\n",
      "Appended 20 new entries to Pred_Data\\SUN_PHARMACEUTICAL_IND_L_predictions_xgboost.csv\n",
      "    âœ… Successfully updated: SUN_PHARMACEUTICAL_IND_L_predictions_xgboost.csv\n",
      "---> Processing ICICI_BANK_LTD.\n",
      "Appended 20 new entries to Pred_Data\\ICICI_BANK_LTD._predictions_xgboost.csv\n",
      "    âœ… Successfully updated: ICICI_BANK_LTD._predictions_xgboost.csv\n",
      "---> Processing INFOSYS_LIMITED\n",
      "Appended 20 new entries to Pred_Data\\INFOSYS_LIMITED_predictions_xgboost.csv\n",
      "    âœ… Successfully updated: INFOSYS_LIMITED_predictions_xgboost.csv\n",
      "---> Processing STATE_BANK_OF_INDIA\n",
      "Appended 20 new entries to Pred_Data\\STATE_BANK_OF_INDIA_predictions_xgboost.csv\n",
      "    âœ… Successfully updated: STATE_BANK_OF_INDIA_predictions_xgboost.csv\n",
      "---> Processing BHARTI_AIRTEL_LIMITED\n",
      "Appended 20 new entries to Pred_Data\\BHARTI_AIRTEL_LIMITED_predictions_xgboost.csv\n",
      "    âœ… Successfully updated: BHARTI_AIRTEL_LIMITED_predictions_xgboost.csv\n",
      "---> Processing ITC_LTD\n",
      "Appended 20 new entries to Pred_Data\\ITC_LTD_predictions_xgboost.csv\n",
      "    âœ… Successfully updated: ITC_LTD_predictions_xgboost.csv\n",
      "---> Processing LARSEN_&_TOUBRO_LTD.\n",
      "Appended 20 new entries to Pred_Data\\LARSEN_&_TOUBRO_LTD._predictions_xgboost.csv\n",
      "    âœ… Successfully updated: LARSEN_&_TOUBRO_LTD._predictions_xgboost.csv\n",
      "---> Processing HINDUSTAN_UNILEVER_LTD.\n",
      "Appended 20 new entries to Pred_Data\\HINDUSTAN_UNILEVER_LTD._predictions_xgboost.csv\n",
      "    âœ… Successfully updated: HINDUSTAN_UNILEVER_LTD._predictions_xgboost.csv\n",
      "\n",
      "All processing complete.\n"
     ]
    }
   ],
   "source": [
    "# updating Prediction file\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ğŸ”® Generating predictions for all equities...\")\n",
    "\n",
    "for ticker, basename in ticker_to_basename.items():\n",
    "    print(f\"---> Processing {basename}\")\n",
    "    \n",
    "    try:\n",
    "        raw_file_name = f\"{basename}_data.csv\"\n",
    "        raw_file_path = os.path.join(raw_data_folder, raw_file_name)\n",
    "        pred_file_name = f\"{basename}_predictions_xgboost.csv\"\n",
    "        pred_file_path = os.path.join(predicted_data_folder, pred_file_name)\n",
    "        \n",
    "        update_predictions_file(raw_file_path, pred_file_path)\n",
    "        print(f\"    âœ… Successfully updated: {pred_file_name}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ Error processing prediction for {basename}: {e}\")\n",
    "\n",
    "print(\"\\nAll processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64fdbf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“ˆ Generating lag features for all equities...\n",
      "================================================================================\n",
      "---> Processing NIFTY_50\n",
      "    âœ… Successfully created: NIFTY_50_lagged.csv\n",
      "---> Processing NIFTY_BANK\n",
      "    âœ… Successfully created: NIFTY_BANK_lagged.csv\n",
      "---> Processing NIFTY_IT\n",
      "    âœ… Successfully created: NIFTY_IT_lagged.csv\n",
      "---> Processing NIFTY_PHARMA\n",
      "    âœ… Successfully created: NIFTY_PHARMA_lagged.csv\n",
      "---> Processing NIFTY_FMCG\n",
      "    âœ… Successfully created: NIFTY_FMCG_lagged.csv\n",
      "---> Processing NIFTY_AUTO\n",
      "    âœ… Successfully created: NIFTY_AUTO_lagged.csv\n",
      "---> Processing NIFTY_METAL\n",
      "    âœ… Successfully created: NIFTY_METAL_lagged.csv\n",
      "---> Processing NIFTY_REALTY\n",
      "    âœ… Successfully created: NIFTY_REALTY_lagged.csv\n",
      "---> Processing NIFTY_ENERGY\n",
      "    âœ… Successfully created: NIFTY_ENERGY_lagged.csv\n",
      "---> Processing NIFTY_FIN_SERVICE\n",
      "    âœ… Successfully created: NIFTY_FIN_SERVICE_lagged.csv\n",
      "---> Processing RELIANCE_INDUSTRIES_LTD\n",
      "    âœ… Successfully created: RELIANCE_INDUSTRIES_LTD_lagged.csv\n",
      "---> Processing TATA_CONSULTANCY_SERV_LT\n",
      "    âœ… Successfully created: TATA_CONSULTANCY_SERV_LT_lagged.csv\n",
      "---> Processing SUN_PHARMACEUTICAL_IND_L\n",
      "    âœ… Successfully created: SUN_PHARMACEUTICAL_IND_L_lagged.csv\n",
      "---> Processing ICICI_BANK_LTD.\n",
      "    âœ… Successfully created: ICICI_BANK_LTD._lagged.csv\n",
      "---> Processing INFOSYS_LIMITED\n",
      "    âœ… Successfully created: INFOSYS_LIMITED_lagged.csv\n",
      "---> Processing STATE_BANK_OF_INDIA\n",
      "    âœ… Successfully created: STATE_BANK_OF_INDIA_lagged.csv\n",
      "---> Processing BHARTI_AIRTEL_LIMITED\n",
      "    âœ… Successfully created: BHARTI_AIRTEL_LIMITED_lagged.csv\n",
      "---> Processing ITC_LTD\n",
      "    âœ… Successfully created: ITC_LTD_lagged.csv\n",
      "---> Processing LARSEN_&_TOUBRO_LTD.\n",
      "    âœ… Successfully created: LARSEN_&_TOUBRO_LTD._lagged.csv\n",
      "---> Processing HINDUSTAN_UNILEVER_LTD.\n",
      "    âœ… Successfully created: HINDUSTAN_UNILEVER_LTD._lagged.csv\n",
      "\n",
      "All lag feature generation complete.\n"
     ]
    }
   ],
   "source": [
    "# --- Loop Through All Equities to Generate Lag Features ---\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ğŸ“ˆ Generating lag features for all equities...\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# We just need the \"basename\" values from the map (e.g., \"NIFTY_50\")\n",
    "for basename in ticker_to_basename.values():\n",
    "    print(f\"---> Processing {basename}\")\n",
    "    \n",
    "    try:\n",
    "        # 1. Construct the path to the prediction file (Input)\n",
    "        #    (This assumes the output from your previous script)\n",
    "        pred_file_name = f\"{basename}_predictions_xgboost.csv\"\n",
    "        pred_file_path = os.path.join(predicted_data_folder, pred_file_name)\n",
    "\n",
    "        # 2. Construct the path for the new lag file (Output)\n",
    "        lag_file_name = f\"{basename}_lagged.csv\"\n",
    "        lag_file_path = os.path.join(lagging_data_folder, lag_file_name)\n",
    "        \n",
    "        # 3. Read the prediction data\n",
    "        data = pd.read_csv(pred_file_path, parse_dates=['Datetime'], index_col='Datetime')\n",
    "        if data.index.tz is not None:\n",
    "            data.index = data.index.tz_localize(None)\n",
    "\n",
    "        # 4. Isolate the 'ActualPrice' column as the base for lags\n",
    "        data_df = data[['ActualPrice']].copy()\n",
    "\n",
    "        # 5. Create the advanced lag features\n",
    "        full_lagged = create_all_advanced_lags(data_df)\n",
    "        if full_lagged.index.tz is not None:\n",
    "            full_lagged.index = full_lagged.index.tz_localize(None)\n",
    "\n",
    "        # 6. Save the new lagged data to the Lag_Data folder\n",
    "        full_lagged.to_csv(lag_file_path)\n",
    "        print(f\"    âœ… Successfully created: {lag_file_name}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"    âš ï¸  Skipping {basename}: Prediction file not found at {pred_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ Error processing lags for {basename}: {e}\")\n",
    "\n",
    "print(\"\\nAll lag feature generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42f99d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Processing ^NSEI (NIFTY_50) ...\n",
      "âœ… Files loaded for NIFTY_50 | Raw: 3942 | Lagged: 3934 | Pred: 3942\n",
      "Found 20 rows with missing 'PredictedPrice' values.\n",
      "âš ï¸ Found 20 missing predictions. Starting update...\n",
      "Starting prediction from index 3914 | datetime: 2025-11-18 09:15:00\n",
      "ğŸ’¾ Saved 20 new predictions so far... (NIFTY_50)\n",
      "All 20 missing predictions saved for NIFTY_50.\n",
      "ğŸ”® Final prediction for NIFTY_50: 26236.27 at 2025-11-20 14:15:00\n",
      "\n",
      "ğŸš€ Processing ^NSEBANK (NIFTY_BANK) ...\n",
      "âœ… Files loaded for NIFTY_BANK | Raw: 3942 | Lagged: 3934 | Pred: 3942\n",
      "Found 20 rows with missing 'PredictedPrice' values.\n",
      "âš ï¸ Found 20 missing predictions. Starting update...\n",
      "Starting prediction from index 3914 | datetime: 2025-11-18 09:15:00\n",
      "ğŸ’¾ Saved 20 new predictions so far... (NIFTY_BANK)\n",
      "All 20 missing predictions saved for NIFTY_BANK.\n",
      "ğŸ”® Final prediction for NIFTY_BANK: 59361.16 at 2025-11-20 14:15:00\n",
      "\n",
      "ğŸš€ Processing ^CNXIT (NIFTY_IT) ...\n",
      "âœ… Files loaded for NIFTY_IT | Raw: 3521 | Lagged: 3513 | Pred: 3521\n",
      "Found 20 rows with missing 'PredictedPrice' values.\n",
      "âš ï¸ Found 20 missing predictions. Starting update...\n",
      "Starting prediction from index 3493 | datetime: 2025-11-18 09:15:00\n",
      "ğŸ’¾ Saved 20 new predictions so far... (NIFTY_IT)\n",
      "All 20 missing predictions saved for NIFTY_IT.\n",
      "ğŸ”® Final prediction for NIFTY_IT: 37123.30 at 2025-11-20 14:15:00\n",
      "\n",
      "ğŸš€ Processing ^CNXPHARMA (NIFTY_PHARMA) ...\n",
      "âœ… Files loaded for NIFTY_PHARMA | Raw: 3519 | Lagged: 3511 | Pred: 3519\n",
      "Found 20 rows with missing 'PredictedPrice' values.\n",
      "âš ï¸ Found 20 missing predictions. Starting update...\n",
      "Starting prediction from index 3491 | datetime: 2025-11-18 09:15:00\n",
      "ğŸ’¾ Saved 20 new predictions so far... (NIFTY_PHARMA)\n",
      "All 20 missing predictions saved for NIFTY_PHARMA.\n",
      "ğŸ”® Final prediction for NIFTY_PHARMA: 22716.93 at 2025-11-20 14:15:00\n",
      "\n",
      "ğŸš€ Processing ^CNXFMCG (NIFTY_FMCG) ...\n",
      "âœ… Files loaded for NIFTY_FMCG | Raw: 3521 | Lagged: 3513 | Pred: 3521\n",
      "Found 20 rows with missing 'PredictedPrice' values.\n",
      "âš ï¸ Found 20 missing predictions. Starting update...\n",
      "Starting prediction from index 3493 | datetime: 2025-11-18 09:15:00\n",
      "ğŸ’¾ Saved 20 new predictions so far... (NIFTY_FMCG)\n",
      "All 20 missing predictions saved for NIFTY_FMCG.\n",
      "ğŸ”® Final prediction for NIFTY_FMCG: 55544.35 at 2025-11-20 14:15:00\n",
      "\n",
      "ğŸš€ Processing ^CNXAUTO (NIFTY_AUTO) ...\n",
      "âœ… Files loaded for NIFTY_AUTO | Raw: 3520 | Lagged: 3512 | Pred: 3520\n",
      "Found 20 rows with missing 'PredictedPrice' values.\n",
      "âš ï¸ Found 20 missing predictions. Starting update...\n",
      "Starting prediction from index 3492 | datetime: 2025-11-18 09:15:00\n",
      "ğŸ’¾ Saved 20 new predictions so far... (NIFTY_AUTO)\n",
      "All 20 missing predictions saved for NIFTY_AUTO.\n",
      "ğŸ”® Final prediction for NIFTY_AUTO: 27600.88 at 2025-11-20 14:15:00\n",
      "\n",
      "ğŸš€ Processing ^CNXMETAL (NIFTY_METAL) ...\n",
      "âœ… Files loaded for NIFTY_METAL | Raw: 3519 | Lagged: 3511 | Pred: 3519\n",
      "Found 20 rows with missing 'PredictedPrice' values.\n",
      "âš ï¸ Found 20 missing predictions. Starting update...\n",
      "Starting prediction from index 3491 | datetime: 2025-11-18 09:15:00\n",
      "ğŸ’¾ Saved 20 new predictions so far... (NIFTY_METAL)\n",
      "All 20 missing predictions saved for NIFTY_METAL.\n",
      "ğŸ”® Final prediction for NIFTY_METAL: 10402.86 at 2025-11-20 14:15:00\n",
      "\n",
      "ğŸš€ Processing ^CNXREALTY (NIFTY_REALTY) ...\n",
      "âœ… Files loaded for NIFTY_REALTY | Raw: 3521 | Lagged: 3513 | Pred: 3521\n",
      "Found 20 rows with missing 'PredictedPrice' values.\n",
      "âš ï¸ Found 20 missing predictions. Starting update...\n",
      "Starting prediction from index 3493 | datetime: 2025-11-18 09:15:00\n",
      "ğŸ’¾ Saved 20 new predictions so far... (NIFTY_REALTY)\n",
      "All 20 missing predictions saved for NIFTY_REALTY.\n",
      "ğŸ”® Final prediction for NIFTY_REALTY: 921.00 at 2025-11-20 14:15:00\n",
      "\n",
      "ğŸš€ Processing ^CNXENERGY (NIFTY_ENERGY) ...\n",
      "âœ… Files loaded for NIFTY_ENERGY | Raw: 3518 | Lagged: 3510 | Pred: 3518\n",
      "Found 20 rows with missing 'PredictedPrice' values.\n",
      "âš ï¸ Found 20 missing predictions. Starting update...\n",
      "Starting prediction from index 3490 | datetime: 2025-11-18 09:15:00\n",
      "ğŸ’¾ Saved 20 new predictions so far... (NIFTY_ENERGY)\n",
      "All 20 missing predictions saved for NIFTY_ENERGY.\n",
      "ğŸ”® Final prediction for NIFTY_ENERGY: 36324.65 at 2025-11-20 14:15:00\n",
      "\n",
      "ğŸš€ Processing NIFTY_FIN_SERVICE.NS (NIFTY_FIN_SERVICE) ...\n",
      "âœ… Files loaded for NIFTY_FIN_SERVICE | Raw: 3521 | Lagged: 3513 | Pred: 3521\n",
      "Found 20 rows with missing 'PredictedPrice' values.\n",
      "âš ï¸ Found 20 missing predictions. Starting update...\n",
      "Starting prediction from index 3493 | datetime: 2025-11-18 09:15:00\n",
      "ğŸ’¾ Saved 20 new predictions so far... (NIFTY_FIN_SERVICE)\n",
      "All 20 missing predictions saved for NIFTY_FIN_SERVICE.\n",
      "ğŸ”® Final prediction for NIFTY_FIN_SERVICE: 27850.09 at 2025-11-20 14:15:00\n",
      "\n",
      "ğŸš€ Processing RELIANCE.NS (RELIANCE_INDUSTRIES_LTD) ...\n",
      "âœ… Files loaded for RELIANCE_INDUSTRIES_LTD | Raw: 3936 | Lagged: 3928 | Pred: 3936\n",
      "Found 20 rows with missing 'PredictedPrice' values.\n",
      "âš ï¸ Found 20 missing predictions. Starting update...\n",
      "Starting prediction from index 3908 | datetime: 2025-11-18 09:15:00\n",
      "ğŸ’¾ Saved 20 new predictions so far... (RELIANCE_INDUSTRIES_LTD)\n",
      "All 20 missing predictions saved for RELIANCE_INDUSTRIES_LTD.\n",
      "ğŸ”® Final prediction for RELIANCE_INDUSTRIES_LTD: 1547.27 at 2025-11-20 14:15:00\n",
      "\n",
      "ğŸš€ Processing TCS.NS (TATA_CONSULTANCY_SERV_LT) ...\n",
      "âœ… Files loaded for TATA_CONSULTANCY_SERV_LT | Raw: 3933 | Lagged: 3925 | Pred: 3933\n",
      "Found 20 rows with missing 'PredictedPrice' values.\n",
      "âš ï¸ Found 20 missing predictions. Starting update...\n",
      "Starting prediction from index 3905 | datetime: 2025-11-18 09:15:00\n",
      "ğŸ’¾ Saved 20 new predictions so far... (TATA_CONSULTANCY_SERV_LT)\n",
      "All 20 missing predictions saved for TATA_CONSULTANCY_SERV_LT.\n",
      "ğŸ”® Final prediction for TATA_CONSULTANCY_SERV_LT: 3154.90 at 2025-11-20 14:15:00\n",
      "\n",
      "ğŸš€ Processing SUNPHARMA.NS (SUN_PHARMACEUTICAL_IND_L) ...\n",
      "âœ… Files loaded for SUN_PHARMACEUTICAL_IND_L | Raw: 3445 | Lagged: 3437 | Pred: 3445\n",
      "Found 20 rows with missing 'PredictedPrice' values.\n",
      "âš ï¸ Found 20 missing predictions. Starting update...\n",
      "Starting prediction from index 3417 | datetime: 2025-11-18 09:15:00\n",
      "ğŸ’¾ Saved 20 new predictions so far... (SUN_PHARMACEUTICAL_IND_L)\n",
      "All 20 missing predictions saved for SUN_PHARMACEUTICAL_IND_L.\n",
      "ğŸ”® Final prediction for SUN_PHARMACEUTICAL_IND_L: 1782.06 at 2025-11-20 14:15:00\n",
      "\n",
      "ğŸš€ Processing ICICIBANK.NS (ICICI_BANK_LTD.) ...\n",
      "âœ… Files loaded for ICICI_BANK_LTD. | Raw: 3934 | Lagged: 3926 | Pred: 3934\n",
      "Found 20 rows with missing 'PredictedPrice' values.\n",
      "âš ï¸ Found 20 missing predictions. Starting update...\n",
      "Starting prediction from index 3906 | datetime: 2025-11-18 09:15:00\n",
      "ğŸ’¾ Saved 20 new predictions so far... (ICICI_BANK_LTD.)\n",
      "All 20 missing predictions saved for ICICI_BANK_LTD..\n",
      "ğŸ”® Final prediction for ICICI_BANK_LTD.: 1383.69 at 2025-11-20 14:15:00\n",
      "\n",
      "ğŸš€ Processing INFY.NS (INFOSYS_LIMITED) ...\n",
      "âœ… Files loaded for INFOSYS_LIMITED | Raw: 3935 | Lagged: 3927 | Pred: 3935\n",
      "Found 20 rows with missing 'PredictedPrice' values.\n",
      "âš ï¸ Found 20 missing predictions. Starting update...\n",
      "Starting prediction from index 3907 | datetime: 2025-11-18 09:15:00\n",
      "ğŸ’¾ Saved 20 new predictions so far... (INFOSYS_LIMITED)\n",
      "All 20 missing predictions saved for INFOSYS_LIMITED.\n",
      "ğŸ”® Final prediction for INFOSYS_LIMITED: 1539.18 at 2025-11-20 14:15:00\n",
      "\n",
      "ğŸš€ Processing SBIN.NS (STATE_BANK_OF_INDIA) ...\n",
      "âœ… Files loaded for STATE_BANK_OF_INDIA | Raw: 3514 | Lagged: 3506 | Pred: 3514\n",
      "Found 20 rows with missing 'PredictedPrice' values.\n",
      "âš ï¸ Found 20 missing predictions. Starting update...\n",
      "Starting prediction from index 3486 | datetime: 2025-11-18 09:15:00\n",
      "ğŸ’¾ Saved 20 new predictions so far... (STATE_BANK_OF_INDIA)\n",
      "All 20 missing predictions saved for STATE_BANK_OF_INDIA.\n",
      "ğŸ”® Final prediction for STATE_BANK_OF_INDIA: 982.32 at 2025-11-20 14:15:00\n",
      "\n",
      "ğŸš€ Processing BHARTIARTL.NS (BHARTI_AIRTEL_LIMITED) ...\n",
      "âœ… Files loaded for BHARTI_AIRTEL_LIMITED | Raw: 3936 | Lagged: 3928 | Pred: 3936\n",
      "Found 20 rows with missing 'PredictedPrice' values.\n",
      "âš ï¸ Found 20 missing predictions. Starting update...\n",
      "Starting prediction from index 3908 | datetime: 2025-11-18 09:15:00\n",
      "ğŸ’¾ Saved 20 new predictions so far... (BHARTI_AIRTEL_LIMITED)\n",
      "All 20 missing predictions saved for BHARTI_AIRTEL_LIMITED.\n",
      "ğŸ”® Final prediction for BHARTI_AIRTEL_LIMITED: 2161.89 at 2025-11-20 14:15:00\n",
      "\n",
      "ğŸš€ Processing ITC.NS (ITC_LTD) ...\n",
      "âœ… Files loaded for ITC_LTD | Raw: 3514 | Lagged: 3506 | Pred: 3514\n",
      "Found 20 rows with missing 'PredictedPrice' values.\n",
      "âš ï¸ Found 20 missing predictions. Starting update...\n",
      "Starting prediction from index 3486 | datetime: 2025-11-18 09:15:00\n",
      "ğŸ’¾ Saved 20 new predictions so far... (ITC_LTD)\n",
      "All 20 missing predictions saved for ITC_LTD.\n",
      "ğŸ”® Final prediction for ITC_LTD: 405.48 at 2025-11-20 14:15:00\n",
      "\n",
      "ğŸš€ Processing LT.NS (LARSEN_&_TOUBRO_LTD.) ...\n",
      "âœ… Files loaded for LARSEN_&_TOUBRO_LTD. | Raw: 3933 | Lagged: 3925 | Pred: 3933\n",
      "Found 20 rows with missing 'PredictedPrice' values.\n",
      "âš ï¸ Found 20 missing predictions. Starting update...\n",
      "Starting prediction from index 3905 | datetime: 2025-11-18 09:15:00\n",
      "ğŸ’¾ Saved 20 new predictions so far... (LARSEN_&_TOUBRO_LTD.)\n",
      "All 20 missing predictions saved for LARSEN_&_TOUBRO_LTD..\n",
      "ğŸ”® Final prediction for LARSEN_&_TOUBRO_LTD.: 4032.91 at 2025-11-20 14:15:00\n",
      "\n",
      "ğŸš€ Processing HINDUNILVR.NS (HINDUSTAN_UNILEVER_LTD.) ...\n",
      "âœ… Files loaded for HINDUSTAN_UNILEVER_LTD. | Raw: 3932 | Lagged: 3924 | Pred: 3932\n",
      "Found 20 rows with missing 'PredictedPrice' values.\n",
      "âš ï¸ Found 20 missing predictions. Starting update...\n",
      "Starting prediction from index 3904 | datetime: 2025-11-18 09:15:00\n",
      "ğŸ’¾ Saved 20 new predictions so far... (HINDUSTAN_UNILEVER_LTD.)\n",
      "All 20 missing predictions saved for HINDUSTAN_UNILEVER_LTD..\n",
      "ğŸ”® Final prediction for HINDUSTAN_UNILEVER_LTD.: 2441.85 at 2025-11-20 14:15:00\n",
      "\n",
      "ğŸ‰ All equities processed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Modelling \n",
    "\n",
    "for equity_ticker_symbol, equity in ticker_to_basename.items():\n",
    "    print(f\"\\nğŸš€ Processing {equity_ticker_symbol} ({equity}) ...\")\n",
    "\n",
    "    try:\n",
    "        raw_data_file = os.path.join(raw_data_folder, f\"{equity}_data.csv\")\n",
    "        predicted_data_file = os.path.join(predicted_data_folder, f\"{equity}_predictions_xgboost.csv\")\n",
    "        lagging_data_file = os.path.join(lagging_data_folder, f\"{equity}_lagged.csv\")\n",
    "\n",
    "        raw_data = pd.read_csv(raw_data_file, parse_dates=['Datetime'], index_col='Datetime')\n",
    "        predicted_data = pd.read_csv(predicted_data_file, parse_dates=['Datetime'], index_col='Datetime')\n",
    "        lagging_data = pd.read_csv(lagging_data_file, parse_dates=['Datetime'], index_col='Datetime')\n",
    "\n",
    "        print(f\"âœ… Files loaded for {equity} | Raw: {len(raw_data)} | Lagged: {len(lagging_data)} | Pred: {len(predicted_data)}\")\n",
    "\n",
    "        num_missing, missing_rows_df = find_missing_predictions(predicted_data_file)\n",
    "\n",
    "        if num_missing == 0:\n",
    "            print(f\"âœ… All predictions are already up-to-date for {equity}.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"âš ï¸ Found {num_missing} missing predictions. Starting update...\")\n",
    "\n",
    "        # --- Determine starting datetime ---\n",
    "        first_missing_datetime = pd.to_datetime(missing_rows_df.index[0])\n",
    "        first_lagged_datetime = pd.to_datetime(lagging_data.index[0])\n",
    "        start_datetime = max(first_missing_datetime, first_lagged_datetime)\n",
    "        start_n = lagging_data.index.get_loc(start_datetime)\n",
    "\n",
    "        print(f\"Starting prediction from index {start_n} | datetime: {start_datetime}\")\n",
    "\n",
    "        # --- Prediction loop ---\n",
    "        for i, n in enumerate(range(start_n, len(lagging_data)), 1):\n",
    "            # Prepare training data\n",
    "            if n > 2000:\n",
    "                train_lagged = lagging_data.iloc[n-2000:n]\n",
    "            else:\n",
    "                train_lagged = lagging_data.iloc[:n]\n",
    "\n",
    "            X_train = train_lagged.drop(columns=['ActualPrice'])\n",
    "            y_train = train_lagged['ActualPrice']\n",
    "\n",
    "            # Train model\n",
    "            model = XGBRegressor(\n",
    "                n_estimators=650,\n",
    "                random_state=42,\n",
    "                colsample_bytree=0.8,\n",
    "                learning_rate=0.06,\n",
    "                max_depth=6,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict next point\n",
    "            test_point = lagging_data.iloc[n]\n",
    "            X_test_point = test_point.drop('ActualPrice').to_frame().T\n",
    "            y_pred = model.predict(X_test_point)[0]\n",
    "\n",
    "            # Store prediction\n",
    "            pred_index = lagging_data.index[n]\n",
    "            if pred_index in predicted_data.index:\n",
    "                predicted_data.at[pred_index, 'PredictedPrice'] = y_pred\n",
    "\n",
    "            # Save every 20 steps\n",
    "            if i % 20 == 0:\n",
    "                predicted_data.to_csv(predicted_data_file)\n",
    "                print(f\"ğŸ’¾ Saved {i} new predictions so far... ({equity})\")\n",
    "\n",
    "        # --- Final save ---\n",
    "        predicted_data.to_csv(predicted_data_file)\n",
    "        print(f\"All {num_missing} missing predictions saved for {equity}.\")\n",
    "\n",
    "        # --- Predict final point (sanity check) ---\n",
    "        train_lagged = lagging_data.iloc[-2000:-1] if len(lagging_data) > 2000 else lagging_data.iloc[:-1]\n",
    "        X_train = train_lagged.drop(columns=['ActualPrice'])\n",
    "        y_train = train_lagged['ActualPrice']\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        last_point = lagging_data.iloc[-1].drop('ActualPrice').to_frame().T\n",
    "        last_pred = model.predict(last_point)[0]\n",
    "        print(f\"ğŸ”® Final prediction for {equity}: {last_pred:.2f} at {lagging_data.index[-1]}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {equity}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\nğŸ‰ All equities processed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de3cee44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Processing ^NSEI (NIFTY_50) ...\n",
      "Loaded 3942 rows from Pred_Data\\NIFTY_50_predictions_xgboost.csv\n",
      "â™»ï¸ Filled 20 missing 'return' values for NIFTY_50.\n",
      "ğŸ’¾ Saved updated data to: Pred_Data\\NIFTY_50_predictions_xgboost.csv\n",
      "\n",
      "ğŸ“Š Processing ^NSEBANK (NIFTY_BANK) ...\n",
      "Loaded 3942 rows from Pred_Data\\NIFTY_BANK_predictions_xgboost.csv\n",
      "â™»ï¸ Filled 20 missing 'return' values for NIFTY_BANK.\n",
      "ğŸ’¾ Saved updated data to: Pred_Data\\NIFTY_BANK_predictions_xgboost.csv\n",
      "\n",
      "ğŸ“Š Processing ^CNXIT (NIFTY_IT) ...\n",
      "Loaded 3521 rows from Pred_Data\\NIFTY_IT_predictions_xgboost.csv\n",
      "â™»ï¸ Filled 20 missing 'return' values for NIFTY_IT.\n",
      "ğŸ’¾ Saved updated data to: Pred_Data\\NIFTY_IT_predictions_xgboost.csv\n",
      "\n",
      "ğŸ“Š Processing ^CNXPHARMA (NIFTY_PHARMA) ...\n",
      "Loaded 3519 rows from Pred_Data\\NIFTY_PHARMA_predictions_xgboost.csv\n",
      "â™»ï¸ Filled 20 missing 'return' values for NIFTY_PHARMA.\n",
      "ğŸ’¾ Saved updated data to: Pred_Data\\NIFTY_PHARMA_predictions_xgboost.csv\n",
      "\n",
      "ğŸ“Š Processing ^CNXFMCG (NIFTY_FMCG) ...\n",
      "Loaded 3521 rows from Pred_Data\\NIFTY_FMCG_predictions_xgboost.csv\n",
      "â™»ï¸ Filled 20 missing 'return' values for NIFTY_FMCG.\n",
      "ğŸ’¾ Saved updated data to: Pred_Data\\NIFTY_FMCG_predictions_xgboost.csv\n",
      "\n",
      "ğŸ“Š Processing ^CNXAUTO (NIFTY_AUTO) ...\n",
      "Loaded 3520 rows from Pred_Data\\NIFTY_AUTO_predictions_xgboost.csv\n",
      "â™»ï¸ Filled 20 missing 'return' values for NIFTY_AUTO.\n",
      "ğŸ’¾ Saved updated data to: Pred_Data\\NIFTY_AUTO_predictions_xgboost.csv\n",
      "\n",
      "ğŸ“Š Processing ^CNXMETAL (NIFTY_METAL) ...\n",
      "Loaded 3519 rows from Pred_Data\\NIFTY_METAL_predictions_xgboost.csv\n",
      "â™»ï¸ Filled 20 missing 'return' values for NIFTY_METAL.\n",
      "ğŸ’¾ Saved updated data to: Pred_Data\\NIFTY_METAL_predictions_xgboost.csv\n",
      "\n",
      "ğŸ“Š Processing ^CNXREALTY (NIFTY_REALTY) ...\n",
      "Loaded 3521 rows from Pred_Data\\NIFTY_REALTY_predictions_xgboost.csv\n",
      "â™»ï¸ Filled 20 missing 'return' values for NIFTY_REALTY.\n",
      "ğŸ’¾ Saved updated data to: Pred_Data\\NIFTY_REALTY_predictions_xgboost.csv\n",
      "\n",
      "ğŸ“Š Processing ^CNXENERGY (NIFTY_ENERGY) ...\n",
      "Loaded 3518 rows from Pred_Data\\NIFTY_ENERGY_predictions_xgboost.csv\n",
      "â™»ï¸ Filled 20 missing 'return' values for NIFTY_ENERGY.\n",
      "ğŸ’¾ Saved updated data to: Pred_Data\\NIFTY_ENERGY_predictions_xgboost.csv\n",
      "\n",
      "ğŸ“Š Processing NIFTY_FIN_SERVICE.NS (NIFTY_FIN_SERVICE) ...\n",
      "Loaded 3521 rows from Pred_Data\\NIFTY_FIN_SERVICE_predictions_xgboost.csv\n",
      "â™»ï¸ Filled 20 missing 'return' values for NIFTY_FIN_SERVICE.\n",
      "ğŸ’¾ Saved updated data to: Pred_Data\\NIFTY_FIN_SERVICE_predictions_xgboost.csv\n",
      "\n",
      "ğŸ“Š Processing RELIANCE.NS (RELIANCE_INDUSTRIES_LTD) ...\n",
      "Loaded 3936 rows from Pred_Data\\RELIANCE_INDUSTRIES_LTD_predictions_xgboost.csv\n",
      "â™»ï¸ Filled 20 missing 'return' values for RELIANCE_INDUSTRIES_LTD.\n",
      "ğŸ’¾ Saved updated data to: Pred_Data\\RELIANCE_INDUSTRIES_LTD_predictions_xgboost.csv\n",
      "\n",
      "ğŸ“Š Processing TCS.NS (TATA_CONSULTANCY_SERV_LT) ...\n",
      "Loaded 3933 rows from Pred_Data\\TATA_CONSULTANCY_SERV_LT_predictions_xgboost.csv\n",
      "â™»ï¸ Filled 20 missing 'return' values for TATA_CONSULTANCY_SERV_LT.\n",
      "ğŸ’¾ Saved updated data to: Pred_Data\\TATA_CONSULTANCY_SERV_LT_predictions_xgboost.csv\n",
      "\n",
      "ğŸ“Š Processing SUNPHARMA.NS (SUN_PHARMACEUTICAL_IND_L) ...\n",
      "Loaded 3445 rows from Pred_Data\\SUN_PHARMACEUTICAL_IND_L_predictions_xgboost.csv\n",
      "â™»ï¸ Filled 20 missing 'return' values for SUN_PHARMACEUTICAL_IND_L.\n",
      "ğŸ’¾ Saved updated data to: Pred_Data\\SUN_PHARMACEUTICAL_IND_L_predictions_xgboost.csv\n",
      "\n",
      "ğŸ“Š Processing ICICIBANK.NS (ICICI_BANK_LTD.) ...\n",
      "Loaded 3934 rows from Pred_Data\\ICICI_BANK_LTD._predictions_xgboost.csv\n",
      "â™»ï¸ Filled 20 missing 'return' values for ICICI_BANK_LTD..\n",
      "ğŸ’¾ Saved updated data to: Pred_Data\\ICICI_BANK_LTD._predictions_xgboost.csv\n",
      "\n",
      "ğŸ“Š Processing INFY.NS (INFOSYS_LIMITED) ...\n",
      "Loaded 3935 rows from Pred_Data\\INFOSYS_LIMITED_predictions_xgboost.csv\n",
      "â™»ï¸ Filled 20 missing 'return' values for INFOSYS_LIMITED.\n",
      "ğŸ’¾ Saved updated data to: Pred_Data\\INFOSYS_LIMITED_predictions_xgboost.csv\n",
      "\n",
      "ğŸ“Š Processing SBIN.NS (STATE_BANK_OF_INDIA) ...\n",
      "Loaded 3514 rows from Pred_Data\\STATE_BANK_OF_INDIA_predictions_xgboost.csv\n",
      "â™»ï¸ Filled 20 missing 'return' values for STATE_BANK_OF_INDIA.\n",
      "ğŸ’¾ Saved updated data to: Pred_Data\\STATE_BANK_OF_INDIA_predictions_xgboost.csv\n",
      "\n",
      "ğŸ“Š Processing BHARTIARTL.NS (BHARTI_AIRTEL_LIMITED) ...\n",
      "Loaded 3936 rows from Pred_Data\\BHARTI_AIRTEL_LIMITED_predictions_xgboost.csv\n",
      "â™»ï¸ Filled 20 missing 'return' values for BHARTI_AIRTEL_LIMITED.\n",
      "ğŸ’¾ Saved updated data to: Pred_Data\\BHARTI_AIRTEL_LIMITED_predictions_xgboost.csv\n",
      "\n",
      "ğŸ“Š Processing ITC.NS (ITC_LTD) ...\n",
      "Loaded 3514 rows from Pred_Data\\ITC_LTD_predictions_xgboost.csv\n",
      "â™»ï¸ Filled 20 missing 'return' values for ITC_LTD.\n",
      "ğŸ’¾ Saved updated data to: Pred_Data\\ITC_LTD_predictions_xgboost.csv\n",
      "\n",
      "ğŸ“Š Processing LT.NS (LARSEN_&_TOUBRO_LTD.) ...\n",
      "Loaded 3933 rows from Pred_Data\\LARSEN_&_TOUBRO_LTD._predictions_xgboost.csv\n",
      "â™»ï¸ Filled 20 missing 'return' values for LARSEN_&_TOUBRO_LTD..\n",
      "ğŸ’¾ Saved updated data to: Pred_Data\\LARSEN_&_TOUBRO_LTD._predictions_xgboost.csv\n",
      "\n",
      "ğŸ“Š Processing HINDUNILVR.NS (HINDUSTAN_UNILEVER_LTD.) ...\n",
      "Loaded 3932 rows from Pred_Data\\HINDUSTAN_UNILEVER_LTD._predictions_xgboost.csv\n",
      "â™»ï¸ Filled 20 missing 'return' values for HINDUSTAN_UNILEVER_LTD..\n",
      "ğŸ’¾ Saved updated data to: Pred_Data\\HINDUSTAN_UNILEVER_LTD._predictions_xgboost.csv\n",
      "\n",
      "ğŸ‰ All equities processed for 'return' column update successfully!\n"
     ]
    }
   ],
   "source": [
    "# Return Calculation Loop\n",
    "\n",
    "for equity_ticker_symbol, equity in ticker_to_basename.items():\n",
    "    print(f\"\\nğŸ“Š Processing {equity_ticker_symbol} ({equity}) ...\")\n",
    "\n",
    "    try:\n",
    "        predicted_data_file = os.path.join(predicted_data_folder, f\"{equity}_predictions_xgboost.csv\")\n",
    "\n",
    "        # Skip missing files\n",
    "        if not os.path.exists(predicted_data_file):\n",
    "            print(f\"âš ï¸ File not found: {predicted_data_file}\")\n",
    "            continue\n",
    "\n",
    "        # Load data\n",
    "        predicted_data = pd.read_csv(predicted_data_file, parse_dates=['Datetime'], index_col='Datetime')\n",
    "\n",
    "        print(f\"Loaded {len(predicted_data)} rows from {predicted_data_file}\")\n",
    "\n",
    "        # --- Check required columns ---\n",
    "        required_cols = {'PredictedPrice', 'ActualPrice'}\n",
    "        if not required_cols.issubset(predicted_data.columns):\n",
    "            print(f\"âŒ Missing columns in {equity}: {required_cols - set(predicted_data.columns)}\")\n",
    "            continue\n",
    "\n",
    "        # --- Compute or fill 'return' column ---\n",
    "        if 'return' not in predicted_data.columns:\n",
    "            predicted_data['return'] = (\n",
    "                (predicted_data['PredictedPrice'] - predicted_data['ActualPrice']) / predicted_data['ActualPrice']\n",
    "            )\n",
    "            print(f\"ğŸ†• 'return' column created for {equity}.\")\n",
    "        else:\n",
    "            missing_mask = predicted_data['return'].isna()\n",
    "            if missing_mask.any():\n",
    "                predicted_data.loc[missing_mask, 'return'] = (\n",
    "                    (predicted_data.loc[missing_mask, 'PredictedPrice'] - predicted_data.loc[missing_mask, 'ActualPrice'])\n",
    "                    / predicted_data.loc[missing_mask, 'ActualPrice']\n",
    "                )\n",
    "                print(f\"â™»ï¸ Filled {missing_mask.sum()} missing 'return' values for {equity}.\")\n",
    "            else:\n",
    "                print(f\"âœ… 'return' column already complete for {equity}.\")\n",
    "\n",
    "        # --- Save updated file ---\n",
    "        predicted_data.to_csv(predicted_data_file, index=True)\n",
    "        print(f\"ğŸ’¾ Saved updated data to: {predicted_data_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {equity}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\nğŸ‰ All equities processed for 'return' column update successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
